
# Table of Contents

- [Table of Contents](#table-of-contents)
- [Developer Document](#developer-document)
  - [API of federated learning](#api-of-federated-learning)
    - [Job Scheduler](#job-scheduler)
      - [Job](#job)
      - [Status](#status)
      - [HyperParameters](#hyperparameters)
      - [ScriptsConfig](#scriptsconfig)
      - [Resource](#resource)
      - [Parameters](#parameters)
      - [CheckpointsList](#checkpointslist)
      - [CheckPoint](#checkpoint)
      - [Extenders](#extenders)
      - [SecureAlgorithm](#securealgorithm)
      - [Optimizer](#optimizer)
      - [JobList](#joblist)
      - [HttpResponse](#httpresponse)
      - [Operations](#operations)
        - [create job](#create-job)
        - [update job](#update-job)
        - [delete job](#delete-job)
        - [start job](#start-job)
        - [stop job](#stop-job)
        - [get job](#get-job)
        - [get jobs](#get-jobs)
        - [health check](#health-check)
    - [Model Manager](#model-manager)
      - [Model](#model)
      - [ModelDetail](#modeldetail)
      - [VersionInfo](#versioninfo)
      - [ModelList](#modellist)
      - [HttpResponse](#httpresponse-1)
      - [Operations](#operations-1)
        - [create model](#create-model)
        - [get model](#get-model)
        - [get models](#get-models)
        - [get model by id](#get-model-by-id)
        - [delete model](#delete-model)
        - [delete model by id](#delete-model-by-id)
        - [update model](#update-model)
        - [update model by id](#update-model-by-id)
        - [health check](#health-check-1)
  - [Client SDK](#client-sdk)
    - [load_weights(model)](#load_weightsmodel)
    - [commit_weights(model, optimizer=None)](#commit_weightsmodel-optimizernone)
    - [commit_metrics(metrics)](#commit_metricsmetrics)
    - [get_dataset_path(name)](#get_dataset_pathname)
    - [get_parameter(key)](#get_parameterkey)
    - [get_parameters()](#get_parameters)
    - [put_parameter(key, value)](#put_parameterkey-value)
    - [put_parameters(parameters)](#put_parametersparameters)
    - [get_file(filename, dserialize_func=None, **kwargs)](#get_filefilename-dserialize_funcnone-kwargs)
    - [put_file(filename, content, serialize_func=None, **kwargs)](#put_filefilename-content-serialize_funcnone-kwargs)
    - [create_optimizer(**kwargs)](#create_optimizerkwargs)
  - [Component Startup Configuration](#component-startup-configuration)
    - [Coordinator](#coordinator)
      - [Command Line](#command-line)
      - [Config File](#config-file)
      - [ENVS](#envs)
    - [Client](#client)
      - [Command Line](#command-line-1)
      - [Config file](#config-file-1)
      - [ENVS](#envs-1)
    - [Selector](#selector)
      - [Command Line](#command-line-2)
      - [Config file](#config-file-2)
        - [ExtenderConfig](#extenderconfig)
      - [ENVS](#envs-2)
    - [Job Scheduler](#job-scheduler-1)
      - [ENVS](#envs-3)
    - [Model Manager](#model-manager-1)
      - [ENVS](#envs-4)



------

# Developer Document

This document mainly describes the interface, configuration, parameters, etc. There are four parts:

- API of federated learning
- Client SDK
- Component launch configuration
- Protocol buffers



## API of federated learning

We provide APIs to access job scheduler and model manager components, mainly some CRUD operations. All the interfaces comply with the HTTP protocol. 

### Job Scheduler

job scheduler is used for manage federated jobs, the objects definition as follows:

#### Job

| name             | type              | property    | description                                                  |
| ---------------- | :---------------- | ----------- | ------------------------------------------------------------ |
| id               | string            | required    | The id of federated job, is unique in namespace              |
| description      | string            | optional    | The description of federated job                             |
| create_time      | string            | -           | Create time of this federated job (generated by server)      |
| model_path       | string            | conditional | The init model path in the storage<br>Note:  model_path、model_id、checkpoint_id are mutually exclusive. You only need to fill in one. If all fields are filled in, then the priority will be: checkpoint_id > model_id > model_path |
| model_id         | string            | conditional | The init model id, you can get the model id through model manager.<br>Note:  model_path、model_id、checkpoint_id are mutually exclusive. You only need to fill in one. If all fields are filled in, then the priority will be: checkpoint_id > model_id > model_path |
| checkpoint_id    | string            | conditional | The checkpoint_id, you can get the checkpoint_id through model manager.<br/>Note:  model_path、model_id、checkpoint_id are mutually exclusive. You only need to fill in one. If all fields are filled in, then the priority will be: checkpoint_id > model_id > model_path |
| status           | `Status`          | -           | The current state of federated job, set by the server        |
| runtime          | string            | required    | The runtime of model used in the federated job. Currently supporting “pytorch”, “keras” |
| clients          | string            | optional    | The ip:port address of clients to join into the federated training.<br>seperated by ',' , for example : “192.168.0.1:8080,192.168.0.2:8080” |
| resource         | `Resource`        | optional    | The required client resource to running the federated job    |
| port             | int               | optional    | The port of server service, used to report the job state     |
| hyper_parameters | `HyperParameters` | optional    | The hyper parameters of federated job. If not configured, will be filled with default training  parameters |
| task_entry       | string            | conditional | The training enterypoint in the client , should correspond to the scripts name already on the client at startup<br>Note: This is mutually exclusive with scripts configuration |
| scripts          | `ScriptsConfig`   | conditional | The training scripts to broadcast to all the clients. This configuration is suitable for the scene that clients has no scripts in local.<br>Note: This is mutually exclusive with task_entry configuration |
| ssl              | string            | optional    | The ssl store path, used for secure transfer for grpc        |
| parameters       | `Parameters`      | optional    | The parameters that need to be passed to all training clients, need to be customized by the user |
| extenders        | `Extenders`       | optional    | The extender interface configuration, through this interface, the custom extended interface scripts and functions can be injected into the federation process |
| secure_algorithm | `SecureAlgorithm` | optional    | Federal job security algorithm configuration. If configured, the job will protect the intermediate data of the job under the corresponding secure computing method. |
| checkpoints      | `CheckpointsList` | optional    | The checkpoints generated during the federated job training process, are convenient for users to select the checkpoint for next running corresponding to the checkpoint_id |
| datasets         | string            | optional    | The dataset to use for the job, when there are multiple datasets, seperated by ',', for example: "dataset1, dataset2" |
| output           | string            | required    | The output path of the checkpoint and metrics after job finished |
| random_client    | bool              | optional    | Whether to randomly choose from suitable clients<br>Default is  false |
| untrained_first  | bool              | optional    | When selecting clients for the job, whether those not participating in training is preferred<br>Default is false |
| redundancy       | float             | optional    | Redundancy when selecting devices. For example, 1.5 means selecting at most 1.5 times the number of cleints in each round of configuration; the value ranges from 1.0 to 2.0.<br>Default 1.0 means that there is no redundancy |
| optimizer        | `Optimizer`       | optional    | Optimizer cofiguration, currently for non iid datasets, you can use fedprox, scaffold two optimizers |

The definition of objects involved above as follows:

#### Status

| name     | type   | property | description                                                  |
| -------- | ------ | -------- | ------------------------------------------------------------ |
| state    | string | -        | The status of the federation job, which has the following status: QUEUED，STARTING，RUNNING，FINISHED，FAILED，DELETING |
| reason   | string | -        | If the federated job is in the FAILED state, this field will give the exception reason |
| progress | int    | -        | The progress of the federation job, a value from 0 to 100    |

#### HyperParameters

| name                 | type  | property | description                                                  |
| -------------------- | ----- | -------- | ------------------------------------------------------------ |
| max_round_num        | int   | optional | The maximum number of running rounds for federated jobs, default is 10 |
| client_num           | int   | optional | The number of clients required to run federated jobs, default is 1 |
| threshold_client_num | int   | optional | The minimum number of clients that the federated job runs successfully in each round, default is 1 |
| evaluate_interval    | int   | optional | Federated job evaluation interval, how many rounds to run evaluation once, default is 2 |
| save_interval        | int   | optional | Federated job model save interval, how many rounds to save the checkpoint, default is 5 |
| round_timeout        | int   | optional | The timeout for each round of federated jobs waiting for client results, unit is seconds, default is 3600 |
| learning_rate        | float | optional | Learning rate for federated jobs, default is 1.0             |

#### ScriptsConfig

| name        | type   | property | description                                                  |
| ----------- | ------ | -------- | ------------------------------------------------------------ |
| path        | string | required | The relative path where the script is located                |
| config_file | string | required | The configuration file required for federated jobs to run tasks on the client side |

#### Resource

| name       | type  | property | description                                                  |
| ---------- | ----- | -------- | ------------------------------------------------------------ |
| worker_num | int   | optional | How many workers are needed for parallel training when the federated job runs on the client, the default is 1 |
| cpu        | float | optional | The number of CPU resources required for each worker participating in training on the client, the default value is 1.0 |
| gpu        | int   | optional | The number of GPU resources required for each worker participating in training on the client, the default value is 0 |
| memory     | int   | optional | The number of memory resources required for each worker participating in the training on the client, unit is MB, the default is 1000MB |

#### Parameters

```
This parameter is passed to the user training or evaluation scripts, and will be provided as a command line argument. This paramters is dict with key-value. 
For example, if you provide this config as follows, then the commad will be with the form: 		
		python3 srcipt.py –key value1 -k value2 -v
```

| name | type   | property | description        |
| ---- | ------ | -------- | ------------------ |
| –key | value1 | optional | paramaeter 1       |
| -k   | value2 | optional | parameter 2        |
| -v   | None   | optional | single parameter 3 |

#### CheckpointsList

| name | type         | property | description                                       |
| ---- | ------------ | -------- | ------------------------------------------------- |
| id   | `CheckPoint` | required | Details of the checkpoint corresponding to the id |

#### CheckPoint

| name     | type   | property | description                                                  |
| -------- | ------ | -------- | ------------------------------------------------------------ |
| accuracy | float  | required | The accuracy of this checkpoint after joint evaluation on the federated dataset |
| path     | string | required | The relative path of the checkpoint file in the namespace working directory |

#### Extenders

| name        | type   | property | description                                                  |
| ----------- | ------ | -------- | ------------------------------------------------------------ |
| script_path | string | optional | The path to the script file that implements the extension interface. (If this field is empty, other fields are ignored) |
| broadcast   | string | optional | The function name of the broadcast interface in the script. This function should return two parameters , which are custom file and custom parameters, both in the form of dict. And these files and params will be sent to each client |
| aggregate   | string | optional | The function name of the aggregate interface in the script. This function's input is the updates uploaded by the client, which can be customized for aggregation calculation |
| finish      | string | optional | The function name of the finish interface in the script. This function is executed after the current federated round. Users can customize the final aggregated results, such as saving or converting to other format |

#### SecureAlgorithm

| name              | type   | property | algorithm | description                                                  |
| ----------------- | ------ | -------- | --------- | ------------------------------------------------------------ |
| type              | string | required | --        | Type of security algorithm, currently supported: "DP", "SSA"<br>DP is Differential Privacy<br>SSA is Secure Aggregate |
| noise_multiplier  | float  | required | DP        | Add the Gaussian noise, which is the variance of the Gaussian distribution |
| adding_same_noise | bool   | optional | DP        | When adding noise to the model, whether to add the same noise to all weights |
| threshold         | int    | optional | SSA       | The minimum threshold for the number of clients participating in secret sharing, the minimum value is 2, the maximum value is threshold_num defined in HyperParameters |
| mode              | string | optional | SSA       | onemask or doublemask mode in ssa。onemask mode is more suitable for cross-slio scenarios and does not support client disconnection;<br>doublemask is more suitable for cross-device scenarios, supports client disconnection, and is more secure |
| use_same_mask     | bool   | optional | SSA       | When use_same_mask is True, each layer will use the same encryption mask. When the weight of the model is very regular, the attacker is easy to crack; otherwise, each layer uses a different encryption mask, which is more secure, and the default is false. |

#### Optimizer

| name   | type   | property | description                                                  |
| ------ | ------ | -------- | ------------------------------------------------------------ |
| name   | string | required | The name of the optimizer, currently supported: "fedprox", "scaffold" |
| params | dict   | optional | Optimizer parameters (see the table of below)                |

| name          | type  | property | algorithm | description                                                  |
| ------------- | ----- | -------- | --------- | ------------------------------------------------------------ |
| mu            | float | optional | fedprox   | Correction term coefficient, to correct the difference between the local model and the server model, the recommended range is 0~1, 0 means no correction;<br>default is 0.6 |
| learning_rate | float | optional | --        | Local training learning rate                                 |
| batch_size    | int   | optional | scaffold  | The batch size used when training the local model            |
| sample_num    | int   | optional | scaffold  | The number of samples used in this round when training the local model |

#### JobList

| name | type | property | description                                           |
| ---- | ---- | -------- | ----------------------------------------------------- |
| jobs | list | -        | List of federated jobs, each element of list is `Job` |

#### HttpResponse

| name   | type   | property | description                                    |
| ------ | ------ | -------- | ---------------------------------------------- |
| state  | string | -        | Status: "SUCCESSFUL", "FAILED"                 |
| reason | string | -        | If status is "FAILED", giving the error reason |



#### Operations

the operations is defined as follows

##### create job

Description: create a federated job.

HTTP Request:

```
POST /api/v1/namespaces/{namespace}/jobs
```

Parameters :

| name               | type   | required | description                         |
| ------------------ | ------ | -------- | ----------------------------------- |
| namespace(in path) | string | yes      | the belonging namespace of this job |
| body               | `Job`  | yes      | the details of job configuration    |

Response:

| code | body           | description                                                  |
| ---- | -------------- | ------------------------------------------------------------ |
| 201  | `HttpResponse` | Successfully created federated job                           |
| 403  | `HttpResponse` | Failed to create a job, such as the job already exists, the namespace does not exist, the job parameter verification fails, etc. |
| 500  | `HttpResponse` | Internal server error                                        |



##### update job

Description: Update a federated job.

HTTP Request:

```
PUT /api/v1/namespaces/{namespace}/jobs/{job_id}
```

Parameters :

| name               | type   | required | description                         |
| ------------------ | ------ | -------- | ----------------------------------- |
| namespace(in path) | string | yes      | the belonging namespace of this job |
| job_id(in path)    | string | yes      | the unique id of job                |
| body               | `Job`  | yes      | the details of job configuration    |

Response:

| code | body           | description                                                  |
| ---- | -------------- | ------------------------------------------------------------ |
| 200  | `HttpResponse` | Successfully modified federated job                          |
| 403  | `HttpResponse` | Modifying the job failed, such as the job does not exist, the namespace does not exist, the job parameter verification fails, etc. |
| 500  | `HttpResponse` | Internal server error                                        |



##### delete job

Description: Delete a federated job

HTTP Request:

```
DELETE /api/v1/namespaces/{namespace}/jobs/{job_id}
```

Parameters :

| name               | type   | required | description                         |
| ------------------ | ------ | -------- | ----------------------------------- |
| namespace(in path) | string | yes      | the belonging namespace of this job |
| job_id(in path)    | string | yes      | the unique id of job                |

Response:

| code | body           | description                                                  |
| ---- | -------------- | ------------------------------------------------------------ |
| 200  | `HttpResponse` | The federated job was deleted successfully, or the job does not exist |
| 500  | `HttpResponse` | Internal server error                                        |



##### start job

Description: Start a federated job to running.

HTTP Request:

```
PUT /api/v1/namespaces/{namespace}/jobs/{job_id}:start
```

Parameters :

| name               | type   | required | description                         |
| ------------------ | ------ | -------- | ----------------------------------- |
| namespace(in path) | string | yes      | the belonging namespace of this job |
| job_id(in path)    | string | yes      | the unique id of job                |

Response:

| code | body           | description                                                  |
| ---- | -------------- | ------------------------------------------------------------ |
| 200  | `HttpResponse` | Federated job started successfully                           |
| 403  | `HttpResponse` | Failed to start the job, such as the job does not exist, the namespace does not exist, etc. |
| 500  | `HttpResponse` | Internal server error                                        |



##### stop job

Description: Stop a federated job.

HTTP Request:

```
PUT /api/v1/namespaces/{namespace}/jobs/{job_id}:stop
```

Parameters :

| name               | type   | required | description                         |
| ------------------ | ------ | -------- | ----------------------------------- |
| namespace(in path) | string | yes      | the belonging namespace of this job |
| job_id(in path)    | string | yes      | the unique id of job                |

Response:

| code | body           | description                                                  |
| ---- | -------------- | ------------------------------------------------------------ |
| 200  | `HttpResponse` | Successfully stopped federated job                           |
| 403  | `HttpResponse` | Failed to stop the job, such as the job does not exist, the namespace does not exist, etc. |
| 500  | `HttpResponse` | Internal server error                                        |



##### get job

Description: Get the detailed info of a job.

HTTP Request:

```
GET /api/v1/namespaces/{namespace}/jobs/{job_id}
```

Parameters :

| name               | type   | required | description                         |
| ------------------ | ------ | -------- | ----------------------------------- |
| namespace(in path) | string | yes      | the belonging namespace of this job |
| job_id(in path)    | string | yes      | the unique id of job                |

Response:

| code | body           | description                                                  |
| ---- | -------------- | ------------------------------------------------------------ |
| 200  | `Job`          | The federated job is successfully obtained and the job information is returned |
| 404  | `HttpResponse` | Failed to get job, such as job does not exist, namespace does not exist, etc. |
| 500  | `HttpResponse` | Internal server error                                        |



##### get jobs

Description: Get all the jobs info of one namespace.

HTTP Request:

```
GET /api/v1/namespaces/{namespace}/jobs
```

Parameters :

| name               | type   | required | description        |
| ------------------ | ------ | -------- | ------------------ |
| namespace(in path) | string | yes      | the namespace name |

Response:

| code | body           | description                                                  |
| ---- | -------------- | ------------------------------------------------------------ |
| 200  | `JobList`      | Get all the federated jobs successfully, return job information list |
| 500  | `HttpResponse` | Internal server error                                        |



##### health check

Description: Health check is used to judge whether the job scheduler is working normally.

HTTP Request:

```
GET /api/v1/health
```

Parameters :

None

Response:

| code | body | description                        |
| ---- | ---- | ---------------------------------- |
| 200  | 'OK' | job scheduler is workinng normally |



### Model Manager

The model manager used to manage the model meteadta in user-space in the federated learning system, including the initial model introduced by the user, the checkpoint generated during the training process, and the final trained model, etc. 

```
Note: Model management only manages the meta information of the model. The upload and download of the model data need to access API according to your backend data storage scheme. If your backend supports s3 standard object storage, then we strongly recommend that you use the 'cli' tool we provide. The 'cli' tool provide a complete model management solution, including the data downlond and upload.
However, if you use other backend storage solutions, you should wrap a script yourself to provide full model management functionality, especially the data upload and download. At the sametime, access our model managers API to maintain your model data metadata.
```

objects definition as follows:

#### Model

| name        | type   | property    | description                                                  |
| :---------- | :----- | :---------- | :----------------------------------------------------------- |
| name        | string | required    | The name of created model                                    |
| version     | string | required    | The version of created model                                 |
| runtime     | string | required    | The runtime of created model                                 |
| description | string | optional    | The description of created model                             |
| namespace   | string | optional    | The namespace of created model<br>Default is 'default 'nampspace |
| progress    | int    | optional    | The current progress of model data. When created model, the model should be uploaded to storege server, and this field means  the progress, you can use the update opertion to update the progress. And when the progress is 100, means the model is ready for use. |
| state       | string | optional    | The state of model, support 'unready', 'ready', 'error', 'deleting'. Note: only ready model can be used for federated job |
| model_path  | string | conditional | The path of model in the storage, use this field means the created model is already in storage server, only need to copy to user path.<br>Note: the model_path is mutually exclusive with file_name, file_name means user will upload the model to storage server |
| file_name   | string | conditional | The file name of model, if the model still in user local disk, then should upload the model to the storage server. |

#### ModelDetail

| name         | type          | property | desrcription                                                 |
| :----------- | :------------ | :------- | :----------------------------------------------------------- |
| name         | string        | required | The name of model                                            |
| runtime      | string        | required | The runtime of model                                         |
| namespace    | string        | required | The namespace of model                                       |
| id           | string        | required | The unique id of model                                       |
| state        | string        | required | The current state of model, support 'unready', 'ready', 'error', 'deleting'. |
| version_info | `VersionInfo` | required | The version info of this model                               |
| storage_info | tuple         | required | The storage info of this model, the tuple is format with (namespace, path), the path is releative to the namespace directory |
| model_path   | string        | optional | The origin model path when created                           |
| file_name    | string        | optional | The file name of model when created                          |
| error_msg    | string        | optional | The error reason if model state is error                     |

#### VersionInfo

| name        | type   | property | description                     |
| ----------- | ------ | -------- | ------------------------------- |
| version     | string | required | The version name of the model   |
| time        | string | required | The create time of this version |
| description | string | optional | The description of this version |

#### ModelList

| name   | type | property | description                                      |
| ------ | ---- | -------- | ------------------------------------------------ |
| models | list | -        | The list of model, each element is `ModelDetail` |

#### HttpResponse

| name   | type   | property | description                                    |
| ------ | ------ | -------- | ---------------------------------------------- |
| state  | string | -        | Status: "SUCCESSFUL", "FAILED"                 |
| reason | string | -        | If status is "FAILED", giving the error reason |



#### Operations

the operations is defined as follows

##### create model

Description: Create a model

HTTP Request:

```
POST /api/v1/namespaces/{namespace}/models
```

Parameters :

| name               | type    | required | description                           |
| ------------------ | ------- | -------- | ------------------------------------- |
| namespace(in path) | string  | yes      | the belonging namespace of this model |
| body               | `Model` | yes      | the configuration of model            |

Response:

| code    | body           | description                                                  |
| ------- | -------------- | ------------------------------------------------------------ |
| 201     | `ModelDetail`  | Model created successfully                                   |
| 400     | `HttpResponse` | Failed to create model, such as configuration error, data type is not equal |
| 404     | `HttpResponse` | Failed to create model, namespace does not exist             |
| 500,503 | `HttpResponse` | Internal server error                                        |



##### get model

Description: Get a model

```
Note: A model may have many versions. If version is not specified, then will return all the versions of model, otherwise will return the specified version of model.
```

HTTP Request:

```
GET /api/v1/namespaces/{namespace}/models/{model_name}?version=
```

Parameters :

| name                | type   | required | description                           |
| ------------------- | ------ | -------- | ------------------------------------- |
| namespace(in path)  | string | yes      | the belonging namespace of this model |
| model_name(in path) | string | yes      | the name of this model                |
| version(in query)   | string | no       | the version name of this model        |

Response:

| code    | body           | description                  |
| ------- | -------------- | ---------------------------- |
| 200     | `ModelList`    | Model obtained successfully  |
| 404     | `HttpResponse` | model or namespace not exist |
| 500,503 | `HttpResponse` | Internal server error        |



##### get models

Description: Get all models in one namespace

HTTP Request:

```
GET /api/v1/namespaces/{namespace}/models
```

Parameters :

| name               | type   | required | description             |
| ------------------ | ------ | -------- | ----------------------- |
| namespace(in path) | string | yes      | the namespace of models |

Response:

| code    | body           | description                                      |
| ------- | -------------- | ------------------------------------------------ |
| 200     | `ModelList`    | Successfully fetched all models in one namesapce |
| 404     | `HttpResponse` | namespace not exist                              |
| 500,503 | `HttpResponse` | Internal server error                            |



##### get model by id

Description: Get a model through its model-id

```
Note: After model created success, each model(version) will be given a unique model id, and you can access the model through this id.
```

HTTP Request:

```
GET /api/v1/models?model_id=
```

Parameters :

| name               | type   | required | description             |
| ------------------ | ------ | -------- | ----------------------- |
| model_id(in query) | string | yes      | the namespace of models |

Response:

| code    | body           | description                               |
| ------- | -------------- | ----------------------------------------- |
| 200     | `ModelDetail`  | succcess, return the model detail in body |
| 404     | `HttpResponse` | namespace not exist                       |
| 500,503 | `HttpResponse` | service internal error or unavailable     |



##### delete model

Description: Delete a model

```
Note: A model may have many versions. If version is not specified, then will delete all the versions of model, otherwise will only detele the specified version of model.
```

HTTP Request:

```
DELETE /api/v1/namespaces/{namespace}/models/{model_name}?version=
```

Parameters :

| name                | type   | required | description                             |
| ------------------- | ------ | -------- | --------------------------------------- |
| namespace(in path)  | string | yes      | the belonging namespace of this model   |
| model_name(in path) | string | yes      | the name of this model                  |
| version(in query)   | string | no       | the specific version name of this model |

Response:

| code    | body           | description                           |
| ------- | -------------- | ------------------------------------- |
| 200     | None           | delete model succcess                 |
| 404     | `HttpResponse` | model not exist                       |
| 500,503 | `HttpResponse` | service internal error or unavailable |



##### delete model by id

Description: Delete a model through its model-id

```
Note: After model created success, each model(version) will be given a unique model id, and you can access the model through this id.
```

HTTP Request:

```
DELETE /api/v1/models?model_id=
```

Parameters :

| name               | type   | required | description            |
| ------------------ | ------ | -------- | ---------------------- |
| model_id(in query) | string | yes      | the unique id of model |

Response:

| code    | body           | description                           |
| ------- | -------------- | ------------------------------------- |
| 200     | None           | delete succcess                       |
| 404     | `HttpResponse` | namespace not exist                   |
| 500,503 | `HttpResponse` | service internal error or unavailable |



##### update model

Description: Update a model

```
Note: A model may have many versions. When you update a model, you must set the model version, otherwise the operation will failed.
```

HTTP Request:

```
PUT /api/v1/namespaces/{namespace}/models/{model_name}?version=
```

Parameters :

| name                | type   | required | description                             |
| ------------------- | ------ | -------- | --------------------------------------- |
| namespace(in path)  | string | yes      | the belonging namespace of this model   |
| model_name(in path) | string | yes      | the name of this model                  |
| version(in query)   | string | yes      | the specific version name of this model |

Response:

| code    | body           | description                                    |
| ------- | -------------- | ---------------------------------------------- |
| 200     | `ModelDetail`  | update model succcess, return the model detail |
| 404     | `HttpResponse` | model not exist                                |
| 500,503 | `HttpResponse` | service internal error or unavailable          |



##### update model by id

Description: Update a model through its model-id

```
Note: After model created success, each model(version) will be given a unique model id, and you can access the model through this id.
```

HTTP Request:

```
PUT /api/v1/models?model_id=
```

Parameters :

| name               | type   | required | description            |
| ------------------ | ------ | -------- | ---------------------- |
| model_id(in query) | string | yes      | the unique id of model |

Response:

| code    | body           | description                           |
| ------- | -------------- | ------------------------------------- |
| 200     | `ModelDetail`  | update succcess                       |
| 404     | `HttpResponse` | namespace not exist                   |
| 500,503 | `HttpResponse` | service internal error or unavailable |



##### health check

Description: Health check is used to judge whether the model manager is working normally.

HTTP Request:

```
GET /api/v1/health
```

Parameters :

None

Response:

| code | body | description                        |
| ---- | ---- | ---------------------------------- |
| 200  | 'OK' | model manager is workinng normally |



## Client SDK

The sdk provides a way to interact with the federation framework. It is convenient for users to write their own federated training programs, greatly simplifies the development process. we provide the following SDK interfaces:

### load_weights(model)

- Description: load the global weights, which broadcast from the server.

  ```
  The global weights is broadcast to all the clients by server when each federated round starts. the client will load this global weights as the init weights for training or evaluating.
  Current we support tf and torch runtimes, so you use the models of these two runtimes.
  ```

- inputs:

  | name  | type                    | required | description                                            |
  | ----- | ----------------------- | -------- | ------------------------------------------------------ |
  | model | tf model<br>torch model | yes      | the local training model, supporting tf or torch model |

- outputs:

  None



### commit_weights(model, optimizer=None)

- Description: Commit trained weights to server.

  ```
  Commit local trained weights to federated framework by this interface, and the framework will calculate delta weights(the difference between local weights and the global weights) before send it to server.
  ```

- inputs:

  | name      | type                    | required | description                                                  |
  | --------- | ----------------------- | -------- | ------------------------------------------------------------ |
  | model     | tf model<br>torch model | yes      | the local training model, supporting tf or torch model       |
  | optimizer | object(optimizer)       | no       | the optimizer object instance used in local training, supporting tf or torch optimizer |

- outputs:

  None

  

### commit_metrics(metrics)

- Description: Commit metrics to server.

  ```
  After local training or evaluating finished, typically there will be some metrics for server to analysis, such as loss, acccury. You can use this interface to directly send the metrics to server.
  Note the metrics should be organized as a dict.
  ```

- inputs:

  | name    | type | required | description                                                  |
  | ------- | ---- | -------- | ------------------------------------------------------------ |
  | metrics | dict | yes      | A dictionary stored the metrics data after train or evaluate. For example, the dict keys could include:<br>- sample_num int32,<br/>- spend_time int32,<br/>- loss float,<br/>- accuracy float,<br/>- precision float,<br/>- recall_rate float<br>or other values. |

- outputs:

  None

  

### get_dataset_path(name)

- Description: Get the path of the dataset by the dataset name.

  ```
  In federated learning scene, the dataset store in clients. So when client setup, it will load dataset's mapping configuration file, which map the dataset name to the dataset path.
  Then when the federated job starts, it could get the dataset through this interface.
  ```

- inputs:

  | name | type   | required | description                                                  |
  | ---- | ------ | -------- | ------------------------------------------------------------ |
  | name | string | yes      | A index name of the dataset you want to obtain for local training, the path of dataset is from configuration file. |

- outputs:

  path(string): the path to store the dataset.

  

### get_parameter(key)

- Description: Get a parameter from server.

  ```
  The parameters is defined in coordinator extender config, which is user self-deined.
  Coordinator will broadcast them to clients. and user can get one of these parameters through this interface.
  The parameters are organized as dict, get it through its key.
  ```

- inputs:

  | name | type   | required | description          |
  | ---- | ------ | -------- | -------------------- |
  | key  | string | yes      | The key of parameter |

- outputs:

  Value: return the value of the parameter, None if key not exist.

  

### get_parameters()

- Description: Get all the parameters from the server.

  ```
  The parameters is defined in coordinator extender config, which is user self-deined.
  Coordinator will broadcast them to clients. and user can get these parameters through this interface.
  The parameters are organized as dict, return all parameters as a dict.
  ```

- inputs:

  None

- outputs:

  Parameters(dict): return all the parameters as a dict.

  

### put_parameter(key, value)

- Description: Put a parameter to server.

  ```
  The parameters, which generated in the local task, will be sent to server by this interface. Typically used for user self-defined aggregation, some calculations require additional parameters.
  Note that using this will append the parameter to old ones if you call this function several times. All the parameters will be organized as a dict to sent server.
  ```

- inputs:

  | name  | type   | required | description            |
  | ----- | ------ | -------- | ---------------------- |
  | key   | string | yes      | The key of parameter   |
  | value | --     | yes      | The value of parameter |

- outputs:

  None

  

### put_parameters(parameters)

- Description: Put paramters to server, which parameters is already organized as a dict.

  ```
  The parameters, which generated in the local task, will be sent to server by this interface. Typically used for user self-defined aggregation, some calculations require additional parameters.
  Note that this interface require parameters to be organized as a dict. It's similar to put_paramter().
  ```

- inputs:

  | name       | type | required | description                             |
  | ---------- | ---- | -------- | --------------------------------------- |
  | parameters | dict | yes      | all the parameters organized as a dict. |

- outputs:

  None

  

### get_file(filename, dserialize_func=None, **kwargs)

- Description: Get a file from server.

  ```
  The files should be defined in coordinator extender config, which is user-defined. The Coordinator will broadcast these files to the clients, then you can get the file through this interface. Typically used for user-defined calculations.
  If you have several files, you should call this function several times.
  ```

- inputs:

  | name            | type     | required | description                                                  |
  | --------------- | -------- | -------- | ------------------------------------------------------------ |
  | filename        | string   | yes      | the name of file you want to get                             |
  | dserialize_func | function | no       | if need, you can pass a function that used to deserialize the file content |
  | kwargs          | dict     | no       | arguments need to pass to the dserialize function            |

- outputs:

  data: the content of the file (after dserialize if need)

  

### put_file(filename, content, serialize_func=None, **kwargs)

- Description: Put a file to server.

  ```
  The files, which generated in the local task can be sent to server by this interface, typically used for user-defined aggregation.
  ```

- inputs:

  | name           | type     | required | description                                                 |
  | -------------- | -------- | -------- | ----------------------------------------------------------- |
  | filename       | string   | yes      | the file name                                               |
  | content        | --       | yes      | the content of the file                                     |
  | serialize_func | function | no       | if need pass a function to serializethe content before send |
  | kwargs         | dict     | no       | arguments need to pass to the serialize function            |

- outputs:

  None

  

### create_optimizer(**kwargs)

- Description: Create an optimizer specific to Federated Learning

  ```
  Here are some optimizers for federated learning, such as fedProx, SCAFFOLD etc. And it could be more helpful than tranditonal optimizers in some specific areas.
  Current we support fedProx, SCAFFOLD, which is able to converge under Non-IID circumstances.
  ```

- inputs:

  | name   | type | required | description                                                  |
  | ------ | ---- | -------- | ------------------------------------------------------------ |
  | kwargs | dict | no       | parameters that need to pass the optimzier for initialization |

- outputs:

  return an instance of optimizer object.



## Component Startup Configuration

Some components of Federated learning need some startup configurations. Each component will be described in detail below.

### Coordinator

The Configuration can be passed in through the command line with args or configuration file. However, the command line only support some basic configurations to startup, if you need a complete configuration, you should use a config file. The detailed description is as follows.

#### Command Line

| args name   | type   | required | description                                                  |
| ----------- | ------ | -------- | ------------------------------------------------------------ |
| job_name    | string | yes      | job name, the federated job name.                            |
| description | string | no       | some detailed information for this job.                      |
| output      | string | no       | job result output directory, such as the checkpoints, final model etc, will be saved in this directory. <br>Default is under current work dir. |
| host        | string | no       | IP address to serve for gRPC service.<br>Default is localhost |
| port        | int    | no       | port to listen on for gRPC API, the range is 1024~65535. <br>Default port is 55051. |
| clients     | string | yes      | Config clients to participate in this job. Using ip:port to represent one client service address, split by ","<br/>For example: 1 client      "127.0.0.1:8888"<br/>                        2 clients    "127.0.0.1:8888, 192.0.0.1:7777" |
| task_entry  | string | yes      | Client task entrypoint, used to specify task name to client. Typically is the script entrypoint name of the training task. |
| model_path  | string | yes      | Local path of model, Which is the initial global model to broadcast to client for training. |
| runtime     | string | yes      | Model runtime used for loading and training model, allowed model runtime: (tensorflow, pytorch). <br/>More runtimes will be supported in future versions. |
| log_level   | string | no       | Log level, support [DEBUG, INFO, WARNING, ERROR].<br>Default is INFO |
| ssl         | string | no       | ssl path, If use gRPCs, you must set the ssl path. the path should have certificate files. [here](https://grpc.io/docs/guides/auth/) is how to create certificate files and using gRPCs. |
| config_file | string | no       | Path to the configuration file. More detailed configuration can be configured in the configuration file, such as hyper parameters, algorithms etc. If used, configured args above will be replaced if the configuration file contains the same args. |



#### Config File

In addition to supporting the above command line parameters, the file also supports following configurations. Config file fomat is `json`.

```
Note: The command line args is a sub-set of config file. If you set same args both in command line and config file, the command line will be ignored.
we highly recommand to use the configuration file.
```

| args name        | type              | required | description                                                  |
| ---------------- | ----------------- | -------- | ------------------------------------------------------------ |
| hyper_parameters | `HyperParameters` | no       | The hyper parameters of federated training. If not configured, will be filled with default training  parameters |
| parameters       | `Parameters`      | no       | The parameters that need to be passed to all training clients, need to be customized by the user |
| datasets         | string            | no       | The dataset to use for the job, when there are multiple datasets, seperated by ',', for example: "dataset1, dataset2" |
| resource         | `Resource`        | no       | The required client resource to running the federated training |
| extender         | `Extenders`       | no       | The extender interface configuration, through this interface, the custom extended interface scripts and functions can be injected into the federation process |
| secure_algorithm | `SecureAlgorithm` | no       | Federated security algorithm configuration. If configured, the training process will protect the intermediate data of the job under the corresponding secure computing method. |
| scripts          | `ScriptConfig`    | no       | The training scripts to broadcast to all the clients. This configuration is suitable for the scene that clients has no scripts in local |
| optimizer        | `Optimizer`       | no       | Optimizer cofiguration, currently for non iid datasets, you can use fedprox, scaffold two optimizers |



#### ENVS

```
Note: Environment variables are usually configured before startup. Usually, some service addresses, constants, etc. are configured in the environment variables. If a container environment is used, it can be set when the container starts.
```

| ENV                        | Default     | Description                                                  |
| -------------------------- | ----------- | ------------------------------------------------------------ |
| REPORT_PERIOD              | 10          | The time interval for the client to report its own status information， unit is second. Typically, the more stable the client can set the larger value |
| JOB_SCHEDULER_ADDRESS      | None        | If the Job Scheduler component exists, set the service address(ip:port). If you set this address, then federated job process will be reported regularly |
| SELECTOR_ADDRESS           | None        | The selector component address, if set this address, the coordinator will choose clients for federated job from the selector's interface |
| CKPT_ROOT_PATH             | checkpoints | Default directory name to save the checkpoint during the federated training process. |
| DEPLOYMENT_WAY             | cloud       | The deployment method of the coordinator, support cloud or local. If cloud, the should set the COORDINATOR_WORKSPACE_PATH, which is the root work directory of federated job. |
| COORDINATOR_WORKSPACE_PATH | /fl         | The mounted root directory of federated job in the cloud storage. |



### Client

The Configuration can be passed in through the command line with args or configuration file. However, the command line only support some basic configurations to startup, if you need a complete configuration, you should use a config file. The detailed description is as follows.

```
Note: we highly recommand to use the configuration file.
```

#### Command Line

| args name         | type   | required | description                                                  |
| ----------------- | ------ | -------- | ------------------------------------------------------------ |
| host              | string | no       | Client listen host, default is '0.0.0.0'                     |
| port              | int    | no       | Client listen port, default is 22000                         |
| server            | string | yes      | The address of server, format is ip:port, where to report the the train or evaluate result.<br>For example: 192.0.0.1:9000 |
| lmdb_path         | string | yes      | LMDB path, an local path to used to save task metadata and status. Note: the path must be exist, could be an empty directory |
| workspace         | string | yes      | Client's workspace path, where used to save some temporary files. These temporary files are generated during the task running, such as checkpoints, task result, etc. |
| platform          | string | no       | Client's platform, support [k8s, linux], default is linux |
| task_config_entry | string | yes      | This is a path to store task_config.json. The task_config.json indicate the path of the entrypoint scripts that the task need to run |
| storage_quota     | int    | no       | The storage quota of client (unit is MB), which limit the size of workspace. When storage_quota is exceeded, the long-standing temporary files in workspace will be deleted |
| log_level         | string | no       | Log level, support [DEBUG, INFO, WARNING, ERROR]<br>default is INFO |
| ssl               | string | no       | ssl path, If use gRPCs, you must set the ssl path. the path should have certificate files. [here](https://grpc.io/docs/guides/auth/) is how to create certificate files and using gRPCs. |
| datasets          | string | yes      | A path to store a JSON file, in which describes the mapping relationship between dataset name and dataset path. This file indicates the dataset supported by the client for federated job |
| config_file       | string | no       | Path to the configuration file. More detailed configuration can be configured in the configuration file. Configured args above will be replaced if the configuration file contains the same args. |



#### Config file

In addition to supporting the above command line parameters, the file also supports following configurations. Config file fomat is `json`.

```
Note: The command line args is a sub-set of config file. If you set same args both in command line and config file, the command line will be ignored.
```

| args name            | type   | required | description                                                  |
| -------------------- | ------ | -------- | ------------------------------------------------------------ |
| external_address     | string | no       | The IP address and port of the client's external service, Default is host:port |
| registration         | bool   | no       | Whether the client is registered to the selector component. Default is true |
| label                | string | no       | Client's label, which can be used to classify and filter devices |
| runtime              | string | no       | Client supported runtimes, which can be used to classify and filter devices |
| max_task_parallelism | int    | no       | The maximum number of concurrent federated job on the client |
| username             | string | no       | Client's username, used to authentication. Only used when registration is true. |
| password             | string | no       | Client's password, used to authentication. Only used when registration is true. |
| public_key           | string | no       | The path to store the public key,  see [here](https://www.pycrypto.org/) how to generate public keys. |
| private_key          | string | no       | The path to store the private key, see [here](https://www.pycrypto.org/) how to generate private keys. |
| certificate          | string | no       | The path to store the certificate, see [here](https://pypi.org/project/pyOpenSSL/) how to generate and load certificate. |

##### 

#### ENVS

```
Note: Environment variables are usually configured before startup. If a container environment is used, it can be set when the container starts.
```

| ENV                          | Default | Description                                                  |
| ---------------------------- | ------- | ------------------------------------------------------------ |
| CONTAINER_EXECUTOR_IMAGE     | None    | If the client's task execution environment is kubernetes, then should specify the image address |
| WORKER_PORT                  | 8050    | Service port when the task is executed                       |
| WAIT_WORKER_FINISHED_TIMEOUT | 300     | Maximum time to wait for a task to complete, if not, the task will be stopped forcely |
| WORKER_HTTP_PROXY            | None    | Set up pod environment of http proxy if need                 |
| WORKER_HTTPS_PROXY           | None    | Set up pod environment of https proxy if need                |



### Selector

The selector component is mainly used to select the suitable clients for the federated job. The detailed configuration instructions are as follows:

```
Note: The selector component is not mandatory. you can also directly configure the client's service address to join the federated job. However, when you don't know the client, and there are a large number of clients, especially in the cross-device scenarios, such as mobile phone, sensors.
```

#### Command Line

| args name      | type   | required | description                                                  |
| -------------- | ------ | -------- | ------------------------------------------------------------ |
| host           | string | no       | IP address to serve for gRPC API., default is '0.0.0.0'      |
| port           | int    | no       | Port to listen on for gRPC API, the range is 1024~65535. Default port is 50055. |
| log_level      | string | no       | Log level, support [DEBUG, INFO, WARNING, ERROR].<br/>Default is INFO |
| auth_client    | string | no       | Verify the legitimacy of the client. If True, the client should send its certificate or public key. Only the clients pass the authentication can join the federaed job. Default is False. |
| root_cert      | string | no       | The root certificate path, root certificate is used to verify the legitimacy of client, see [here](https://pypi.org/project/pyOpenSSL/) how to generate and load certificate. |
| ssl            | string | no       | ssl path, If use gRPCs, you must set the ssl path. the path should have certificate files. [here](https://grpc.io/docs/guides/auth/) is how to create certificate files and using gRPCs. |
| optimal_select | bool   | no       | Whether the client will be selected by optimal strategy. If set False, the selector will random select client after filter. If set True, you can config the strategy in config file, or using the default strategy. |
| config_file    | string | no       | Path to the configuration file. More detailed configuration can be configured in the configuration file. Configured args above will be replaced if the configuration file contains the same args. |



#### Config file

```
Note: The command line args is a sub-set of config file. If you set same args both in command line and config file, the command line will be ignored.
You can config the strategies and extensions for evaluating and filtering clients.
```

| args name | type | required | description                                                  |
| --------- | ---- | -------- | ------------------------------------------------------------ |
| strategy  | dict | no       | Strategy is used to score the clients, prioritize clients for federated job.<br>Strategy is composed with a few evaluators, with dict format, such as:<br/>        Key: evaluator_name     Value: weight_value<br/>        {<br/>            "resource": 1,<br/>            "data": 1<br/>        }<br/>The Strategy will use every evaluator in the config to score the client, then add up all the scores, which as the final score of client. |
| extenders | dict | no       | Extender is used to extend the process client selection, it will be called after the strategy execution. Support extenders = ["filter", "score"]. For example:<br>{<br/>                "filter": `ExtenderConfig`,<br/>                "score": `ExtenderConfig`<br/> } |

##### ExtenderConfig

| name        | type   | required | description                                    |
| ----------- | ------ | -------- | ---------------------------------------------- |
| mode        | string | yes      | The form of extender, current support ["file"] |
| path        | string | yes      | The absolute path of extension script          |
| method_name | string | yes      | The name of the extension function             |



#### ENVS

| ENV           | Default | Description                                                  |
| ------------- | ------- | ------------------------------------------------------------ |
| SINGLE_HEART  | 300     | The time interval at which the selector requires the client to report, if the client is a single device |
| CLUSTER_HEART | 600     | The time interval at which the selector requires the client to report, if the client is a cluster, which means more stable |



### Job Scheduler

```
Note: Job Scheduler is mainly responsible for scheduling tasks and interacting with multiple modules. There are no startup parameters, mainly some environment variable configurations.
```

#### ENVS

| ENV                           | Default | Description                                                  |
| ----------------------------- | ------- | ------------------------------------------------------------ |
| SELECTOR_ADDRESS              | None    | The service address of Selector Component                    |
| ROUTE_REGISTER_ADDRESS        | None    | The service address of Proxy Component                       |
| CLOUD_OS                      | k8s     | The system operating environment of each component           |
| K8S_ADDRESS                   | None    | The service address of Kubernetes                            |
| HTTP_PORT                     | None    | The service port on which this job scheduler component runs  |
| COORDINATOR_IMAGE             | None    | The docker image address of Coordinator component            |
| WORKSPACE_ROOT_PATH           | /fl     | The root directory of all the federated jobs in the storage  |
| STORAGE_PATH                  | None    | The path in the pod that mount the HOST_PATH                 |
| HOST_PATH                     | None    | The local path that needs to be mounted when the job scheduler pod is running |
| JS_NAMESPACE                  | None    | The namespace that job scheduler use                         |
| DEPLOYMENT_WAY                | cloud   | The deployment method of component, default is in kubernetes |
| DB_TYPE                       | mongo   | The type of database, support ["mongo", "postgreSQL"]        |
| COORDINATOR_HEARTBEAT_TIMEOUT | 20      | The maximum time interval reported by the coordinator, if timeout, the coordinator will be deleted, the jod will set to failed |
| MAX_RETRY_TIMES               | 30      | Maximum number of attempts to connect                        |
| COORDINATOR_QUERY_INTERVAL    | 1       | The retry time interval after schedule the coordinator       |
| DB_ADDRESS                    | None    | The service address of database                              |
| DB_USERNAME                   | None    | The username to login the database                           |
| DB_PASSWORD                   | None    | The password to login the database                           |
| DB_NAME                       | None    | The used database name                                       |
| COLLECTION_NAME               | None    | The used db collection name                                  |
| REPORT_PERIOD                 | 10      | The report time interval of coordinator                      |
| JOB_SCHEDULER_ADDRESS         | None    | The service address of Job Scheduler component               |
| MODEL_MANAGER_ADDRESS         | None    | The service address of Model Manager component               |



### Model Manager

#### ENVS

| ENV                | Default    | Description                                                  |
| ------------------ | ---------- | ------------------------------------------------------------ |
| PORT               | 50057      | The service port of this component                           |
| LOG_LEVEL          | INFO       | The log level, support [DEBUG, INFO, WARNING, ERROR]         |
| DB_TYPE            | mongo      | The type of database, support ["mongo", "postgreSQL"]        |
| DB_ADDRESS         | None       | The service address of database                              |
| DB_USERNAME        | None       | The username to login the database                           |
| DB_PASSWORD        | None       | The password to login the database                           |
| DB_NAME            | None       | The used database name                                       |
| DB_COLLECTION_NAME | None       | The used db collection name                                  |
| MOUNT_PATH         | /mnt/minio | The local host path of model storage, this path will be mounted into the component pod(container) |
| MODEL_STORE        | models     | The root path to store the model under the MOUNT_PATH        |
| STORAGE_TYPE       | s3         | The type of backend storage, support ["poisx", "s3"]         |
| STORAGE_ENDPOINT   | None       | The address of backend storage if use s3 object storage      |
| ACCESS_KEY         | None       | The ACCESS_KEY to the standard s3 object storage             |
| SECRET_KEY         | None       | The SECRET_KEY to the standard s3 object storage             |

